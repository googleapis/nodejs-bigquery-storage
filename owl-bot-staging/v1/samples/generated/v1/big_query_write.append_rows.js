// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// ** This file is automatically generated by gapic-generator-typescript. **
// ** https://github.com/googleapis/gapic-generator-typescript **
// ** All changes to this file may be overwritten. **



'use strict';

function main(writeStream) {
  // [START bigquerystorage_v1_generated_BigQueryWrite_AppendRows_async]
  /**
   * This snippet has been automatically generated and should be regarded as a code template only.
   * It will require modifications to work.
   * It may require correct/in-range values for request initialization.
   * TODO(developer): Uncomment these variables before running the sample.
   */
  /**
   *  Required. The write_stream identifies the append operation. It must be
   *  provided in the following scenarios:
   *  * In the first request to an AppendRows connection.
   *  * In all subsequent requests to an AppendRows connection, if you use the
   *  same connection to write to multiple tables or change the input schema for
   *  default streams.
   *  For explicitly created write streams, the format is:
   *  * `projects/{project}/datasets/{dataset}/tables/{table}/streams/{id}`
   *  For the special default stream, the format is:
   *  * `projects/{project}/datasets/{dataset}/tables/{table}/streams/_default`.
   *  An example of a possible sequence of requests with write_stream fields
   *  within a single connection:
   *  * r1: {write_stream: stream_name_1}
   *  * r2: {write_stream: /*omit* /}
   *  * r3: {write_stream: /*omit* /}
   *  * r4: {write_stream: stream_name_2}
   *  * r5: {write_stream: stream_name_2}
   *  The destination changed in request_4, so the write_stream field must be
   *  populated in all subsequent requests in this stream.
   */
  // const writeStream = 'abc123'
  /**
   *  If present, the write is only performed if the next append offset is same
   *  as the provided value. If not present, the write is performed at the
   *  current end of stream. Specifying a value for this field is not allowed
   *  when calling AppendRows for the '_default' stream.
   */
  // const offset = {}
  /**
   *  Rows in proto format.
   */
  // const protoRows = {}
  /**
   *  Rows in arrow format. This is an experimental feature only selected for
   *  allowlisted customers.
   */
  // const arrowRows = {}
  /**
   *  Id set by client to annotate its identity. Only initial request setting is
   *  respected.
   */
  // const traceId = 'abc123'
  /**
   *  A map to indicate how to interpret missing value for some fields. Missing
   *  values are fields present in user schema but missing in rows. The key is
   *  the field name. The value is the interpretation of missing values for the
   *  field.
   *  For example, a map {'foo': NULL_VALUE, 'bar': DEFAULT_VALUE} means all
   *  missing values in field foo are interpreted as NULL, all missing values in
   *  field bar are interpreted as the default value of field bar in table
   *  schema.
   *  If a field is not in this map and has missing values, the missing values
   *  in this field are interpreted as NULL.
   *  This field only applies to the current request, it won't affect other
   *  requests on the connection.
   *  Currently, field name can only be top-level column name, can't be a struct
   *  field path like 'foo.bar'.
   */
  // const missingValueInterpretations = [1,2,3,4]
  /**
   *  Optional. Default missing value interpretation for all columns in the
   *  table. When a value is specified on an `AppendRowsRequest`, it is applied
   *  to all requests on the connection from that point forward, until a
   *  subsequent `AppendRowsRequest` sets it to a different value.
   *  `missing_value_interpretation` can override
   *  `default_missing_value_interpretation`. For example, if you want to write
   *  `NULL` instead of using default values for some columns, you can set
   *  `default_missing_value_interpretation` to `DEFAULT_VALUE` and at the same
   *  time, set `missing_value_interpretations` to `NULL_VALUE` on those columns.
   */
  // const defaultMissingValueInterpretation = {}

  // Imports the Storage library
  const {BigQueryWriteClient} = require('@google-cloud/bigquery-storage').v1;

  // Instantiates a client
  const storageClient = new BigQueryWriteClient();

  async function callAppendRows() {
    // Construct request
    const request = {
      writeStream,
    };

    // Run request
    const stream = await storageClient.appendRows();
    stream.on('data', (response) => { console.log(response) });
    stream.on('error', (err) => { throw(err) });
    stream.on('end', () => { /* API call completed */ });
    stream.write(request);
    stream.end();
  }

  callAppendRows();
  // [END bigquerystorage_v1_generated_BigQueryWrite_AppendRows_async]
}

process.on('unhandledRejection', err => {
  console.error(err.message);
  process.exitCode = 1;
});
main(...process.argv.slice(2));
